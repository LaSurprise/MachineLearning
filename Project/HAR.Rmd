Human Activity Recognition
==========================

## Synopsis

The goal of this project is to build a model that can be used to predict how some persons asked to perform barbell lifts did the exercise. We will also use the model to predict 20 different test cases.    
The data used here is collected from accelerometers on the belt, forearm, arm, and dumbell.   
The data comes from this source : [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har) and was downloaded from Coursera website.    

## Data   
The training dataset [Training](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) is a set of 160 variables and 19622 observations.        
        - The seven first variables describe the context on the exercice : monitoring features    
        - The last one, named classe, is the outcome we will try to predict.  
        - The other variables are used as predictors.    
The test dataset [Testing](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv) has a similar pattern, but his last variable is a problem_id.   

  
## Loading and processing data

###1 - Set work directory and read CSV data.

```{r}
setwd("C:/Users/Lydienne/MachineLearning/Project/")
pml.training <- read.csv("pml-training.csv")
pml.testing <- read.csv("pml-testing.csv")
```

###2 - Select outcome and predictor variables
```{r echo = T}
training <- pml.training [, -c(1,2,3,4,5,6,7)]
testing <- pml.testing [, -c(1,2,3,4,5,6,7)]
```
     
###3 - Check training and testing data

```{r}
str(training)
str(testing)
```
* result : 153 variables (one outcome and 152 predictors)
* training data : some variables are "Factor" instead of "Num", we need to transform them so that they may be used in a proper way.    
* testing data : some variables are "logical" instead of "Num", a transformation is needed too.

###4 - Transform training and testing data

```{r echo = T, warning=FALSE, cache.comments=FALSE, message=FALSE, error=TRUE}
for (i in 1:152) if(class(training[,i])=="factor") training[,i] <- as.numeric(as.character(training[,i]))
for (i in 1:152) if(class(testing[,i])=="logical") testing[,i] <- as.numeric(as.character(testing[,i]))
```

###5 - Preprocessing and Prinicpal Components
####5.1 Remove outcome variable and determine PC
```{r echo = T, warning=FALSE, error=TRUE, message=FALSE}
library("caret")
trainData1 <- training[,-153]
summary(prcomp(trainData1, scale = TRUE))
```

####5.2 Variables with mean equal to NA

```{r echo = T}
means <- colMeans(trainData1, na.rm = TRUE)
which(is.na(means[]) )
```

####5.3 Conclusion
Preprocessing is not possible because we have missing value in some variables.   
So we are going to build model without preprocessing

###6 - Building Model

####6.1 Remove variables with NA values

```{r}
trainData <- training[,-153]
testData <- testing[,-153]
means <- colMeans(testData, na.rm = TRUE)
testData <- testData[,which(!is.na(means[]))]
trainData <- data.frame(cbind(trainData[,which(!is.na(means[]))], classe=training$classe))

```

####6.2 Apply RPART with CARET package and plot result
```{r echo=T, warning=FALSE, error=FALSE, message=FALSE}
library("rattle")
set.seed(1)
CART <- train(classe ~ . ,method="rpart",data=trainData)
print("Classification And Regression Tree Summary")
CART
##print(CART$finalModel)
fancyRpartPlot(CART$finalModel)
```

####6.3 Apply RPART with TREE package and plot result
```{r echo=T, warning=FALSE, error=FALSE, message=FALSE}
library("tree")
set.seed(2)
Tree1 <- tree(classe ~ . ,method="rpart",data=trainData)
plot(Tree1)
text(Tree1, all=TRUE, cex=.6)
```


###7 - Prediction

```{r echo=T, warning=FALSE, error=FALSE}
answers <- predict(CART,testData)
answers
source("pml_write_files.R")
pml_write_files(answers)
```

